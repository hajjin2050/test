{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled27.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1ePABlshwo6Ct0iSvqskBhzKcxeZzmLm9",
      "authorship_tag": "ABX9TyN2plgAsbTBgL0ON+3S/9JN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moonsh2050/test/blob/main/dacon-%20efficien7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-A2TABujaqjS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "outputId": "f44af6b3-00ab-4db8-83e9-c23495d53394"
      },
      "source": [
        "!pip install  torch_poly_lr_decay\r\n",
        "! pip install git+https://github.com/cmpark0126/pytorch-polynomial-lr-decay.git\r\n",
        "\r\n",
        "import torch\r\n",
        "import glob\r\n",
        "import os\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "import pandas as pd\r\n",
        "import cv2\r\n",
        "from tqdm import tqdm\r\n",
        "import numpy as np\r\n",
        "from torchvision import transforms\r\n",
        "import torchvision.models as models\r\n",
        "import torch.nn as nn\r\n",
        "from torch.nn import functional as F\r\n",
        "from sklearn.model_selection import KFold\r\n",
        "import time\r\n",
        "from efficientnet_pytorch import EfficientNet\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from torch_poly_lr_decay import PolynomialLRDecay\r\n",
        "import random\r\n",
        "import albumentations\r\n",
        "\r\n",
        "torch.set_num_threads(1)\r\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "\r\n",
        "# ======================== Dacon Dataset Load ==========================\r\n",
        "labels_df = pd.read_csv('/content/drive/MyDrive/mnist/dirty_mnist_2nd_answer.csv')[:]\r\n",
        "imgs_dir = np.array(sorted(glob.glob('/content/drive/MyDrive/mnist/dirty_mnist_2nd/*')))[:]\r\n",
        "labels = np.array(labels_df.values[:,1:])\r\n",
        "\r\n",
        "test_imgs_dir = np.array(sorted(glob.glob('/content/drive/MyDrive/mnist/dirty_mnist_2nd')))\r\n",
        "\r\n",
        "imgs=[]\r\n",
        "for path in tqdm(imgs_dir[:]):\r\n",
        "    img=cv2.imread(path, cv2.IMREAD_COLOR)\r\n",
        "    imgs.append(img)\r\n",
        "imgs=np.array(imgs)\r\n",
        "\r\n",
        "# 저장소에서 load\r\n",
        "class MnistDataset_v1(Dataset):\r\n",
        "    def __init__(self, imgs_dir=None, labels=None, transform=None, train=True):\r\n",
        "        self.imgs_dir = imgs_dir\r\n",
        "        self.labels = labels\r\n",
        "        self.transform = transform\r\n",
        "        self.train = train\r\n",
        "        pass\r\n",
        "    \r\n",
        "    def __len__(self):\r\n",
        "        # 데이터 총 샘플 수\r\n",
        "        return len(self.imgs)\r\n",
        "    \r\n",
        "    def __getitem__(self, idx):\r\n",
        "        # 1개 샘플 get\r\n",
        "        img = cv2.imread(self.imgs_dir[idx], cv2.IMREAD_COLOR)\r\n",
        "        img = self.transform(img)\r\n",
        "        if self.train==True:\r\n",
        "            label = self.labels[idx]\r\n",
        "            return img, label\r\n",
        "        else:\r\n",
        "            return img\r\n",
        "        \r\n",
        "        pass\r\n",
        "    \r\n",
        "# 메모리에서 load\r\n",
        "class MnistDataset_v2(Dataset):\r\n",
        "    def __init__(self, imgs=None, labels=None, transform=None, train=True):\r\n",
        "        self.imgs = imgs\r\n",
        "        self.labels = labels\r\n",
        "        self.transform = transform\r\n",
        "        self.train=train\r\n",
        "        #(TTA)test data augmentations#\r\n",
        "        self.aug = albumentations.Compose ([ \r\n",
        "                   albumentations.RandomResizedCrop (256, 256), \r\n",
        "                    albumentations.Transpose (p = 0.5), \r\n",
        "                    albumentations.HorizontalFlip (p = 0.5), \r\n",
        "                    albumentations.VerticalFlip (p = 0.5),\r\n",
        "                    albumentations.HueSaturationValue(\r\n",
        "                        hue_shift_limit=0.2, \r\n",
        "                        sat_shift_limit=0.2,\r\n",
        "                        val_shift_limit=0.2, \r\n",
        "                        p=0.5\r\n",
        "                    )\r\n",
        "                ], p=1.)\r\n",
        "        pass\r\n",
        "    \r\n",
        "    def __len__(self):\r\n",
        "        # 데이터 총 샘플 수\r\n",
        "        return len(self.imgs)\r\n",
        "    \r\n",
        "    def __getitem__(self, idx):\r\n",
        "        # 1개 샘플 get1\r\n",
        "        img = self.imgs[idx]\r\n",
        "        img = self.transform(img)\r\n",
        "        \r\n",
        "        if self.train==True:\r\n",
        "            label = self.labels[idx]\r\n",
        "            return img, label\r\n",
        "        else:\r\n",
        "            return img\r\n",
        "\r\n",
        "# ========================= reproduction을 위한 seed 설정=====================\r\n",
        "# https://dacon.io/competitions/official/235697/codeshare/2363?page=1&dtype=recent&ptype=pub\r\n",
        "def seed_everything(seed: int = 42):\r\n",
        "    random.seed(seed)\r\n",
        "    np.random.seed(seed)\r\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\r\n",
        "    torch.manual_seed(seed)\r\n",
        "    torch.cuda.manual_seed(seed)  # type: ignore\r\n",
        "    torch.backends.cudnn.deterministic = True  # type: ignore\r\n",
        "    torch.backends.cudnn.benchmark = True  \r\n",
        "\r\n",
        "\r\n",
        "# ==================== model 정의 ==================================\r\n",
        "# EfficientNet -b0(pretrained)\r\n",
        "# MultiLabel output\r\n",
        "\r\n",
        "class EfficientNet_MultiLabel(nn.Module):\r\n",
        "    def __init__(self, in_channels):\r\n",
        "        super(EfficientNet_MultiLabel, self).__init__()\r\n",
        "        self.network = EfficientNet.from_pretrained('efficientnet-b7', in_channels=in_channels) # b3, b7 \r\n",
        "        self.output_layer = nn.Linear(1000, 26)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = F.relu(self.network(x))\r\n",
        "        x = torch.sigmoid(self.output_layer(x))\r\n",
        "        return x\r\n",
        "\r\n",
        "# ============== 데이터 분리====================================\r\n",
        "# 해당 코드에서는 1fold만 실행\r\n",
        "\r\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\r\n",
        "folds=[]\r\n",
        "for train_idx, valid_idx in kf.split(imgs):\r\n",
        "    folds.append((train_idx, valid_idx))\r\n",
        "\r\n",
        "### seed_everything(42)\r\n",
        "\r\n",
        "# 5개의 fold 모두 실행하려면 for문을 5번 돌리면 됩니다.\r\n",
        "for fold in range(1):\r\n",
        "    model = EfficientNet_MultiLabel(in_channels=3).to(device)\r\n",
        "# model = nn.DataParallel(model)\r\n",
        "    train_idx = folds[fold][0]\r\n",
        "    valid_idx = folds[fold][1]\r\n",
        "\r\n",
        "    train_transform = transforms.Compose([\r\n",
        "        transforms.ToTensor(),\r\n",
        "        transforms.RandomHorizontalFlip(),\r\n",
        "        transforms.RandomVerticalFlip()\r\n",
        "        ])\r\n",
        "    valid_transform = transforms.Compose([\r\n",
        "        transforms.ToTensor(),\r\n",
        "        ])\r\n",
        "\r\n",
        "    epochs=30\r\n",
        "    batch_size=28        # 자신의 VRAM에 맞게 조절해야 OOM을 피할 수 있습니다.\r\n",
        "    \r\n",
        "    # Data Loader\r\n",
        "    train_dataset = MnistDataset_v2(imgs = imgs[train_idx], labels=labels[train_idx], transform=train_transform)\r\n",
        "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\r\n",
        "\r\n",
        "    valid_dataset = MnistDataset_v2(imgs = imgs[valid_idx], labels = labels[valid_idx], transform=valid_transform)\r\n",
        "    valid_loader = DataLoader(dataset=valid_dataset, batch_size=batch_size, shuffle=False) \r\n",
        "    \r\n",
        "    # optimizer\r\n",
        "    # polynomial optimizer를 사용합니다.\r\n",
        "    # \r\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)\r\n",
        "    decay_steps = (len(train_dataset)//batch_size)*epochs\r\n",
        "    scheduler_poly_lr_decay = PolynomialLRDecay(optimizer, max_decay_steps=decay_steps, end_learning_rate=1e-5, power=0.9)\r\n",
        "\r\n",
        "    criterion = torch.nn.BCELoss()\r\n",
        "    \r\n",
        "    epoch_accuracy = []\r\n",
        "    valid_accuracy = []\r\n",
        "    valid_losses=[]\r\n",
        "    valid_best_accuracy=0\r\n",
        "    for epoch in range(epochs):\r\n",
        "        model.train()\r\n",
        "        batch_accuracy_list = []\r\n",
        "        batch_loss_list = []\r\n",
        "        start=time.time()\r\n",
        "        for n, (X, y) in enumerate((train_loader)):\r\n",
        "            X = torch.tensor(X, device=device, dtype=torch.float32)\r\n",
        "            y = torch.tensor(y, device=device, dtype=torch.float32)\r\n",
        "            y_hat = model(X)\r\n",
        "                        \r\n",
        "            optimizer.zero_grad()\r\n",
        "            loss = criterion(y_hat, y)\r\n",
        "            loss.backward()\r\n",
        "            optimizer.step()\r\n",
        "            scheduler_poly_lr_decay.step()\r\n",
        "            \r\n",
        "            y_hat  = y_hat.cpu().detach().numpy()\r\n",
        "            y_hat = y_hat>0.5\r\n",
        "            y = y.cpu().detach().numpy()\r\n",
        "\r\n",
        "            batch_accuracy = (y_hat == y).mean()\r\n",
        "            batch_accuracy_list.append(batch_accuracy)\r\n",
        "            batch_loss_list.append(loss.item())\r\n",
        "\r\n",
        "        model.eval()\r\n",
        "        valid_batch_accuracy=[]\r\n",
        "        valid_batch_loss = []\r\n",
        "        with torch.no_grad():\r\n",
        "            for n_valid, (X_valid, y_valid) in enumerate((valid_loader)):\r\n",
        "                X_valid = torch.tensor(X_valid, device=device)#, dtype=torch.float32)\r\n",
        "                y_valid = torch.tensor(y_valid, device=device, dtype=torch.float32)\r\n",
        "                y_valid_hat = model(X_valid)\r\n",
        "                \r\n",
        "                valid_loss = criterion(y_valid_hat, y_valid).item()\r\n",
        "                \r\n",
        "                y_valid_hat = y_valid_hat.cpu().detach().numpy()>0.5\r\n",
        "                                \r\n",
        "                valid_batch_loss.append(valid_loss)\r\n",
        "                valid_batch_accuracy.append((y_valid_hat == y_valid.cpu().detach().numpy()).mean())\r\n",
        "                \r\n",
        "            valid_losses.append(np.mean(valid_batch_loss))\r\n",
        "            valid_accuracy.append(np.mean(valid_batch_accuracy))\r\n",
        "            \r\n",
        "        if np.mean(valid_batch_accuracy)>valid_best_accuracy:\r\n",
        "            torch.save(model.state_dict(), '/content/drive/MyDrive/vision2/checkpoint/0226_EfficientNetB7-fold{}.pt'.format(fold))\r\n",
        "            valid_best_accuracy = np.mean(valid_batch_accuracy)\r\n",
        "        print('fold : {}\\tepoch : {:02d}\\ttrain_accuracy / loss : {:.5f} / {:.5f}\\tvalid_accuracy / loss : {:.5f} / {:.5f}\\ttime : {:.0f}'.format(fold+1, epoch+1,\r\n",
        "                                                                                                                                              np.mean(batch_accuracy_list),\r\n",
        "                                                                                                                                              np.mean(batch_loss_list),\r\n",
        "                                                                                                                                              np.mean(valid_batch_accuracy), \r\n",
        "                                                                                                                                              np.mean(valid_batch_loss),\r\n",
        "                                                                                                                                              time.time()-start))\r\n",
        "\r\n",
        "# ===================== Test Image 로드 ==========================\r\n",
        "test_imgs=[]\r\n",
        "for path in tqdm(test_imgs_dir):\r\n",
        "    test_img=cv2.imread(path, cv2.IMREAD_COLOR)\r\n",
        "    test_imgs.append(test_img)\r\n",
        "test_imgs=np.array(test_imgs)\r\n",
        "\r\n",
        "test_transform = transforms.Compose([\r\n",
        "        transforms.ToTensor(),\r\n",
        "        ])\r\n",
        "\r\n",
        "\r\n",
        "# ================ Test 추론 =============================\r\n",
        "submission = pd.read_csv('/content/drive/MyDrive/mnist/sample_submission.csv')\r\n",
        "\r\n",
        "with torch.no_grad():\r\n",
        "    for fold in range(1):\r\n",
        "        model = EfficientNet_MultiLabel(in_channels=3).to(device)\r\n",
        "        model.load_state_dict(torch.load('/content/drive/MyDrive/vision2/checkpoint/0226_EfficientNetB7-fold{}.pt'.format(fold)))\r\n",
        "        model.eval()\r\n",
        "\r\n",
        "        test_dataset = MnistDataset_v2(imgs = test_imgs, transform=test_transform, train=False)\r\n",
        "        test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)\r\n",
        "\r\n",
        "        for n, X_test in enumerate(tqdm(test_loader)):\r\n",
        "            X_test = torch.tensor(X_test, device=device, dtype=torch.float32)\r\n",
        "            with torch.no_grad():\r\n",
        "                model.eval()\r\n",
        "                pred_test = model(X_test).cpu().detach().numpy()\r\n",
        "                submission.iloc[n*32:(n+1)*32,1:] += pred_test\r\n",
        "\r\n",
        "# ==================== 제출물 생성 ====================\r\n",
        "submission.iloc[:,1:] = np.where(submission.values[:,1:]>=0.5, 1,0)\r\n",
        "submission.to_csv('/content/drive/MyDrive/vision2/0225_2_base.csv', index=False)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch_poly_lr_decay (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for torch_poly_lr_decay\u001b[0m\n",
            "Collecting git+https://github.com/cmpark0126/pytorch-polynomial-lr-decay.git\n",
            "  Cloning https://github.com/cmpark0126/pytorch-polynomial-lr-decay.git to /tmp/pip-req-build-_ub6ouu0\n",
            "  Running command git clone -q https://github.com/cmpark0126/pytorch-polynomial-lr-decay.git /tmp/pip-req-build-_ub6ouu0\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torch-poly-lr-decay==0.0.1) (1.7.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch->torch-poly-lr-decay==0.0.1) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torch-poly-lr-decay==0.0.1) (3.7.4.3)\n",
            "Building wheels for collected packages: torch-poly-lr-decay\n",
            "  Building wheel for torch-poly-lr-decay (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-poly-lr-decay: filename=torch_poly_lr_decay-0.0.1-cp37-none-any.whl size=3833 sha256=60bc28df93fcfff8809c0540d31a07a4316334c5dabe8472b8739184894ee2fd\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ox9_r960/wheels/5a/b7/09/d748b20c9bdfc768a33c37a28b2ad7dd9ec3e79e5152cb1618\n",
            "Successfully built torch-poly-lr-decay\n",
            "Installing collected packages: torch-poly-lr-decay\n",
            "Successfully installed torch-poly-lr-decay-0.0.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-b615265d7762>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mefficientnet_pytorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEfficientNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_poly_lr_decay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPolynomialLRDecay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'efficientnet_pytorch'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZCI4ROLkXx7",
        "outputId": "8797880b-c7dc-4584-c937-7e836356f296"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}