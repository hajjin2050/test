{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "copying.ipynb",
      "provenance": [],
      "mount_file_id": "1oKFRq3k79Dped1nvuNJe-X2-OBnXGqSs",
      "authorship_tag": "ABX9TyON4viLRLhx2pHdDC/7lkmY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moonsh2050/test/blob/main/vision2_copying.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9lbSlNI_dHx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "ff239a5f-b105-4b2d-f266-5191a09b8769"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import cv2\r\n",
        "from tqdm import tqdm\r\n",
        "import imutils\r\n",
        "import zipfile\r\n",
        "import os\r\n",
        "from PIL import Image\r\n",
        "from typing import Tuple, Sequence, Callable\r\n",
        "import glob\r\n",
        "from sklearn.model_selection import KFold\r\n",
        "import time\r\n",
        "import random\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torchvision.models as models\r\n",
        "from torchvision import transforms\r\n",
        "import torchvision.transforms as T\r\n",
        "from torch.utils.data import DataLoader, Dataset\r\n",
        "from google.colab import output\r\n",
        "\r\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "labels_df = pd.read_csv('/content/gdrive/MyDrive/vision2/dirty_mnist_2nd_answer.csv')[:]\r\n",
        "imgs_dir = np.array(sorted(glob.glob('/content/gdrive/MyDrive/vision2/dirty_mnist/*')))[:]\r\n",
        "labels = np.array(labels_df.values[:,1:])\r\n",
        "\r\n",
        "test_imgs_dir = np.array(sorted(glob.glob('/content/gdrive/MyDrive/vision2/test_dirty_mnist/*')))\r\n",
        "\r\n",
        "labels_df\r\n",
        "imgs_dir\r\n",
        "\r\n",
        "labels.shape\r\n",
        "# (50000, 26)\r\n",
        "class MnistDataset(Dataset):\r\n",
        "    def __init__(self, imgs_dir=None, labels=None, transform=None, train=True):\r\n",
        "        self.imgs_dir = imgs_dir\r\n",
        "        self.labels = labels\r\n",
        "        self.transform = transform\r\n",
        "        self.train = train\r\n",
        "        pass\r\n",
        "    \r\n",
        "    def __len__(self):\r\n",
        "        # 데이터 총 샘플 수\r\n",
        "        return len(self.imgs_dir)\r\n",
        "    \r\n",
        "    def __getitem__(self, idx):\r\n",
        "        # 1개 샘플 get\r\n",
        "        img = cv2.imread(self.imgs_dir[idx], cv2.IMREAD_COLOR)\r\n",
        "        img = self.transform(img)\r\n",
        "        if self.train==True:\r\n",
        "            label = self.labels[idx]\r\n",
        "            return img, label\r\n",
        "        else:\r\n",
        "            return img\r\n",
        "        \r\n",
        "        pass\r\n",
        "\r\n",
        "resnext = torch.hub.load('pytorch/vision:v0.6.0', 'resnext50_32x4d', pretrained=True)\r\n",
        "\r\n",
        "class Resnext(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(Resnext, self).__init__()\r\n",
        "        self.resnext = resnext \r\n",
        "        self.FC = nn.Linear(1000, 26)\r\n",
        "        nn.init.xavier_normal_(self.FC.weight)\r\n",
        "      \r\n",
        "        \r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = self.resnext(x)\r\n",
        "        x = torch.sigmoid(self.FC(x))\r\n",
        "        return x\r\n",
        "\r\n",
        "model = Resnext()\r\n",
        "model\r\n",
        "\r\n",
        "\r\n",
        "kf = KFold(n_splits=5, shuffle=True)\r\n",
        "folds=[]\r\n",
        "for train_idx, valid_idx in kf.split(labels_df):\r\n",
        "    folds.append((train_idx, valid_idx))\r\n",
        "\r\n",
        "train_idx\r\n",
        "valid_idx\r\n",
        "folds[1][1]\r\n",
        "len(folds[1][0])\r\n",
        "\r\n",
        "def seed_everything(seed: int = 42):\r\n",
        "    random.seed(seed)\r\n",
        "    np.random.seed(seed)\r\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\r\n",
        "    torch.manual_seed(seed)\r\n",
        "    torch.cuda.manual_seed(seed)  # type: ignore\r\n",
        "    torch.backends.cudnn.deterministic = True  # type: ignore\r\n",
        "    torch.backends.cudnn.benchmark = True\r\n",
        "\r\n",
        "#seed_everything(42)\r\n",
        "for fold in range(1):\r\n",
        "    model = Resnext().to(device)\r\n",
        "#     model = nn.DataParallel(model)\r\n",
        "    train_idx = folds[fold][0]\r\n",
        "    valid_idx = folds[fold][1]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    train_transform = transforms.Compose([                                \r\n",
        "        transforms.ToTensor(),\r\n",
        "        transforms.RandomHorizontalFlip(),\r\n",
        "        transforms.RandomVerticalFlip(),\r\n",
        "        transforms.Normalize(\r\n",
        "        [0.485, 0.456, 0.406],\r\n",
        "        [0.229, 0.224, 0.225]\r\n",
        "    )\r\n",
        "        ])\r\n",
        "    valid_transform = transforms.Compose([                                 \r\n",
        "        transforms.ToTensor(),\r\n",
        "        transforms.Normalize(\r\n",
        "        [0.485, 0.456, 0.406],\r\n",
        "        [0.229, 0.224, 0.225]\r\n",
        "    )\r\n",
        "        ])\r\n",
        "\r\n",
        "\r\n",
        "    epochs=30\r\n",
        "    batch_size=64        \r\n",
        "    \r\n",
        "    \r\n",
        "    \r\n",
        "    # Data Loader\r\n",
        "train_dataset = MnistDataset(imgs_dir=imgs_dir[train_idx], labels=labels[train_idx], transform=train_transform)\r\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\r\n",
        "\r\n",
        "valid_dataset = MnistDataset(imgs_dir=imgs_dir[valid_idx], labels=labels[valid_idx], transform=valid_transform)\r\n",
        "valid_loader = DataLoader(dataset=valid_dataset, batch_size=32, shuffle=False)  \r\n",
        "    \r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\r\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones= [23,29], gamma=0.5)\r\n",
        "\r\n",
        "criterion = torch.nn.BCELoss()\r\n",
        "    \r\n",
        "epoch_accuracy = []\r\n",
        "valid_accuracy = []\r\n",
        "valid_losses=[]\r\n",
        "valid_best_accuracy=0\r\n",
        "\r\n",
        "best_models=[]\r\n",
        "\r\n",
        "for epoch in range(epochs):\r\n",
        "  with tqdm(train_loader,total=train_loader.__len__(),unit='batch') as train_bar:\r\n",
        "    model.train()\r\n",
        "    batch_accuracy_list = []\r\n",
        "    batch_loss_list = []\r\n",
        "    start=time.time()\r\n",
        "    for n, (X, y) in enumerate((train_bar)):\r\n",
        "        train_bar.set_description(f\"Train Epoch {epoch}\")\r\n",
        "        X = torch.tensor(X, device=device, dtype=torch.float32)\r\n",
        "        y = torch.tensor(y, device=device, dtype=torch.float32)\r\n",
        "        y_hat = model(X)\r\n",
        "            \r\n",
        "            \r\n",
        "        optimizer.zero_grad()\r\n",
        "        loss = criterion(y_hat, y)\r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "      \r\n",
        "        y_hat  = y_hat.cpu().detach().numpy()\r\n",
        "        y_hat = y_hat>0.5\r\n",
        "        y = y.cpu().detach().numpy()\r\n",
        "\r\n",
        "        batch_accuracy = (y_hat == y).mean()\r\n",
        "        batch_accuracy_list.append(batch_accuracy)\r\n",
        "        batch_loss_list.append(loss.item())\r\n",
        "        train_acc = np.mean(batch_accuracy_list)\r\n",
        "            \r\n",
        "        train_bar.set_postfix(train_loss= loss.item(),train_acc = train_acc)\r\n",
        "\r\n",
        "    model.eval()\r\n",
        "    valid_batch_accuracy=[]\r\n",
        "    valid_batch_loss = []\r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "      with tqdm(valid_loader,total=valid_loader.__len__(),unit=\"batch\") as valid_bar:\r\n",
        "        for n_valid, (X_valid, y_valid) in enumerate((valid_bar)):\r\n",
        "            valid_bar.set_description(f\"Valid Epoch {epoch}\")\r\n",
        "            X_valid = torch.tensor(X_valid, device=device)#, dtype=torch.float32)\r\n",
        "            y_valid = torch.tensor(y_valid, device=device, dtype=torch.float32)\r\n",
        "            y_valid_hat = model(X_valid)\r\n",
        "                \r\n",
        "            valid_loss = criterion(y_valid_hat, y_valid).item()\r\n",
        "            \r\n",
        "            y_valid_hat = y_valid_hat.cpu().detach().numpy()>0.5\r\n",
        "                \r\n",
        "                \r\n",
        "            valid_batch_loss.append(valid_loss)\r\n",
        "            valid_batch_accuracy.append((y_valid_hat == y_valid.cpu().detach().numpy()).mean())\r\n",
        "            val_acc=np.mean(valid_batch_accuracy)\r\n",
        "            valid_bar.set_postfix(valid_loss = valid_loss,valid_acc = val_acc)\r\n",
        "              \r\n",
        "        valid_losses.append(np.mean(valid_batch_loss))\r\n",
        "        valid_accuracy.append(np.mean(valid_batch_accuracy))\r\n",
        "\r\n",
        "    scheduler.step()\r\n",
        "\r\n",
        "    if np.mean(valid_batch_accuracy) > 0.87:\r\n",
        "        path = \"/content/gdrive/MyDrive/Colab Notebooks/models/\"\r\n",
        "        MODEL = \"resnext\"\r\n",
        "        torch.save(model, f'{path}_{MODEL}_{valid_loss:2.4f}_epoch_{epoch}.pth')\r\n",
        "\r\n",
        "    if np.mean(valid_batch_accuracy)>valid_best_accuracy:\r\n",
        "        best_model=model\r\n",
        "        valid_best_accuracy = np.mean(valid_batch_accuracy)\r\n",
        "\r\n",
        "best_models.append(best_model)\r\n",
        "\r\n",
        "best_modelss=[]\r\n",
        "model1 = torch.load('/content/gdrive/MyDrive/Colab Notebooks/models/resnext_0.2259_epoch_25.pth')\r\n",
        "best_modelss.append(model1)\r\n",
        "\r\n",
        "test_transform = transforms.Compose([\r\n",
        "        transforms.ToTensor(),\r\n",
        "        transforms.Normalize(\r\n",
        "        [0.485, 0.456, 0.406],\r\n",
        "        [0.229, 0.224, 0.225])\r\n",
        "        ])\r\n",
        "\r\n",
        "submission = pd.read_csv(\"sample_submission.csv\")\r\n",
        "\r\n",
        "for model in best_modelss:\r\n",
        "    with torch.no_grad():\r\n",
        "        model.eval()\r\n",
        "\r\n",
        "        test_dataset = MnistDataset(imgs_dir=test_imgs_dir, transform=test_transform, train=False)\r\n",
        "        test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)\r\n",
        "\r\n",
        "        for n, X_test in enumerate(tqdm(test_loader)):\r\n",
        "            X_test = torch.tensor(X_test, device=device, dtype=torch.float32)\r\n",
        "            with torch.no_grad():\r\n",
        "                model.eval()  \r\n",
        "                pred_test = model(X_test).cpu().detach().numpy()\r\n",
        "                submission.iloc[n*32:(n+1)*32,1:] += pred_test\r\n",
        "submission.iloc[:,1:] = np.where(submission.values[:,1:]>=0.5, 1,0)\r\n",
        "submission\r\n",
        "\r\n",
        "!pip install ttach\r\n",
        "import ttach as tta\r\n",
        "\r\n",
        "\r\n",
        "best_modelss=[]\r\n",
        "model1 = torch.load('/content/gdrive/MyDrive/Colab Notebooks/models/624_resnext_0.2651_epoch_24.pth')\r\n",
        "best_modelss.append(model1)\r\n",
        "\r\n",
        "## tta\r\n",
        "\r\n",
        "submission = pd.read_csv(\"sample_submission.csv\")\r\n",
        "\r\n",
        "for model in best_modelss:\r\n",
        "    with torch.no_grad():\r\n",
        "        model.eval()\r\n",
        "\r\n",
        "        test_dataset = MnistDataset(imgs_dir=test_imgs_dir, transform=test_transform, train=False)\r\n",
        "        test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)\r\n",
        "\r\n",
        "        tta_model=tta.ClassificationTTAWrapper(model,tta.aliases.ten_crop_transform(224,224),merge_mode='mean')\r\n",
        "\r\n",
        "        for n, X_test in enumerate(tqdm(test_loader)):\r\n",
        "            X_test = torch.tensor(X_test, device=device, dtype=torch.float32)\r\n",
        "            with torch.no_grad():\r\n",
        "                model.eval()  \r\n",
        "                pred_test = tta_model(X_test).cpu().detach().numpy()\r\n",
        "                submission.iloc[n*32:(n+1)*32,1:] += pred_test\r\n",
        "\r\n",
        "submission.iloc[:,1:] = np.where(submission.values[:,1:]>=0.5, 1,0)\r\n",
        "submission\r\n",
        "\r\n",
        "submission.to_csv('0223tta2651.csv', index=False)\r\n",
        "\r\n",
        "pred1=pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/02212094.csv')\r\n",
        "pred1.head()\r\n",
        "\r\n",
        "pred2=pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/02212151.csv')\r\n",
        "pred2.head()\r\n",
        "\r\n",
        "pred3=pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/02212259.csv')\r\n",
        "pred3.head()\r\n",
        "\r\n",
        "pred4=pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/best2651.csv')\r\n",
        "pred4.head()\r\n",
        "\r\n",
        "\r\n",
        "pred5=pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/best2951.csv')\r\n",
        "pred5.head()\r\n",
        "\r\n",
        "\r\n",
        "final=((pred1 + pred2 + pred3+pred4+pred5)/5 > 0.5)*1\r\n",
        "final['index']=pred1['index']\r\n",
        "final\r\n",
        "\r\n",
        "final.to_csv('ensemble4.csv', index=False)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-917f8f97cce6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;31m# Data Loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMnistDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimgs_dir\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4B97Uu7k_hMa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}